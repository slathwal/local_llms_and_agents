---
title: "Interact with a CSV file using an LLM model and built-in langchain agent"
author: "Shefali Lathwal"
date: "2025-06-01"
date-modified: last-modified
editor: visual
toc: true
format: html
jupyter: python_langchain
---

::: callout-note
Local Ollama models - gemma3:4b, mistral don't perform accurately on my local machine. Gemma runs but gives unreliable and different answers. Mistral gives the wrong answer and produces an error.

Qwen3:8b and qwen3: 4b are taking a very long time to run, so not using them.

I also tried a coding model - codellama and that is taking an extremely long time as well.

I need to try a more powerful model from OpenAI to see if the problem is with the agent or my local models.
:::

# Get some data

```{python}
import os
import pandas as pd
os.makedirs("data",exist_ok=True)
```

```{python}
!wget https://covidtracking.com/data/download/all-states-history.csv -P ./data/
file_url = "./data/all-states-history.csv"
```

```{python}
df = pd.read_csv("./data/all-states-history.csv").fillna(value = 0)
df.head()
```

# Define the language model

```{python}
from langchain_ollama import ChatOllama
gemma3 = ChatOllama(model = "gemma3:4b", temperature = 0)
mistral = ChatOllama(model = "mistral:latest", temperature = 0)
qwen3 = ChatOllama(model = "qwen3:4b", temperature = 0)
llama = ChatOllama(model = "llama3.1:8b-instruct-q2_K", temperature=0)
codellama = ChatOllama(model= "codellama:7b", temperature = 0)
```

# Use the pandas dataframe agent

Langchain provides a built-in `create_pandas_dataframe_agent` that can be used to interact with a dataframe using

```{python}
from langchain.agents.agent_types import AgentType
from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent

agent = create_pandas_dataframe_agent(llm = gemma3, df = df, verbose = True, allow_dangerous_code = True)

agent.invoke("How many rows are there?")
```

# A more complex example

```{python}
CSV_PROMPT_PREFIX = """
First set the pandas display options to show all the columns, get the column names, then answer the question. You already have the dataframe stored in a variable called df.
"""

CSV_PROMPT_SUFFIX = """
- **ALWAYS** before giving the Final Answer, try another method.
Then reflect on the answers of the two methods you did and ask yourself
if it answers correctly the original question.
If you are not sure, try another method.
- If the methods tried do not give the same result,reflect and
try again until you have two methods that have the same result.
- If you still cannot arrive to a consistent result, say that
you are not sure of the answer.
- If you are sure of the correct answer, create a beautiful
and thorough response using Markdown.
- **DO NOT MAKE UP AN ANSWER OR USE PRIOR KNOWLEDGE,
ONLY USE THE RESULTS OF THE CALCULATIONS YOU HAVE DONE**.
- **ALWAYS**, as part of your "Final Answer", explain how you got
to the answer on a section that starts with: "\n\nExplanation:\n".
In the explanation, mention the column names that you used to get
to the final answer.
"""

QUESTION = """How may patients were hospitalized during July 2020 in the state of Texas, given by code 'TX', and nationwide as the total of all states? Use the hospitalizedIncrease column"""
```

```{python}
agent = create_pandas_dataframe_agent(llm = gemma3, df = df, verbose = True, allow_dangerous_code = True)
agent.invoke(CSV_PROMPT_PREFIX + QUESTION + CSV_PROMPT_SUFFIX)
```

-   Gemma 3 gives incorrect answer. It writes the code, but drops the July 2020 instruction in the middle.
-   It also does the calculation, but assigns an output to the wrong variable during interpretations.
-   In other iterations it fails to call the available tool `python_repl_ast` and generates the wrong tool call.
-   In some iterations, it gives a parsing error as well.

```{python}
agent = create_pandas_dataframe_agent(llm = mistral, df = df, verbose = True, allow_dangerous_code = True)
agent.invoke(CSV_PROMPT_PREFIX + QUESTION + CSV_PROMPT_SUFFIX)
```

Mistral is giving the wrong answer. Mistral is also giving an output parsing error, and I am not sure why. The interesting thing is that mistral is writing the correct code, but getting the wrong answer. I am not sure why that is.

llama3.1:8b-instruct-q2_K does not give an output and gives an error

-   Trying a coding model - codellama to see how it performs, but codellama is too slow, just like qwen3 models.

```{python}
agent = create_pandas_dataframe_agent(llm = codellama, df = df, verbose = True, allow_dangerous_code = True, return_intermediate_steps= True)
agent.invoke(CSV_PROMPT_PREFIX + QUESTION + CSV_PROMPT_SUFFIX)
```

A simple answer is to use a more powerful model by Open AI, but I am not doing that now.

```{python}
# Manual check of the data
df.columns
#df_july_2020 = df[(df["date"].dt.year == 2020 & df["date"].dt.month == 7)]
df_july_2020 = df[(df["date"].dt.year == 2020) & (df["date"].dt.month == 7)]
# all hospitalizations
print("Total hospitalizations in July 2020 nationwide",df_july_2020["hospitalizedIncrease"].sum())
print("Hospitalizations in Texas in July 2020",df_july_2020[df_july_2020["state"]=="TX"]["hospitalizedIncrease"].sum())
```

# Reference:

-   Deeplearning.ai course - Building your own Database Agent
-   https://python.langchain.com/api_reference/experimental/agents/langchain_experimental.agents.agent_toolkits.pandas.base.create_pandas_dataframe_agent.html#langchain_experimental.agents.agent_toolkits.pandas.base.create_pandas_dataframe_agent