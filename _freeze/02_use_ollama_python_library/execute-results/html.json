{
  "hash": "0ce45b69409f6b33165e9e1366fe41a9",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Basics of Ollama - Use Ollama Python library\"\nauthor: \"Shefali Lathwal\"\ndate: \"2025-06-01\"\ndate-modified: last-modified\neditor: visual\ntoc: true\nformat: html\njupyter: python_langchain\nexecute:\n  freeze: auto\n---\n\n\n\n\n# Import the ollama python package\n\n::: {#fcb11cc9 .cell execution_count=1}\n``` {.python .cell-code}\nimport ollama\nfrom IPython.display import Markdown, display\n```\n:::\n\n\n# List the available models\n\n::: {#94888402 .cell execution_count=2}\n``` {.python .cell-code}\nresponse = ollama.list()\nfor item in response:\n    for model in item[1]:\n        print(model[\"model\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ncodellama:7b\nnomic-embed-text:latest\nmistral:latest\nllama3.1:8b-instruct-q2_K\nmxbai-embed-large:latest\ngemma3:4b\n```\n:::\n:::\n\n\n# Chat with a local model\n\n## Chat using the generate API endpoint\n\nGenerate the full response at once\n\n::: {#fdd953ec .cell execution_count=3}\n``` {.python .cell-code}\nres = ollama.generate(model='gemma3:4b', prompt='Why does Canada have a king? Answer in 2 lines')\n```\n:::\n\n\nLook at the answer\n\n::: {#0c09d549 .cell execution_count=4}\n``` {.python .cell-code}\nMarkdown(res[\"response\"])\n```\n\n::: {.cell-output .cell-output-display .cell-output-markdown execution_count=4}\nCanada doesn‚Äôt actually *have* a king! The monarch (currently King Charles III) is Canada‚Äôs Head of State, represented by a Governor-General who acts on the monarch‚Äôs behalf. \n\nIt‚Äôs a historical holdover from Canada‚Äôs time as a British colony.\n:::\n:::\n\n\nGenerate a streaming response\n\n::: {#7232bdcf .cell execution_count=5}\n``` {.python .cell-code}\nres = ollama.generate(model='gemma3:4b', prompt='Tell me about USA? Answer in 2 lines', stream = True)\n```\n:::\n\n\nLook at the answer\n\n::: {#986014b3 .cell execution_count=6}\n``` {.python .cell-code}\nfor chunk in res:\n    print(chunk[\"response\"], end = \"\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThe United States of America is a large, diverse country known for its powerful economy, democratic government, and iconic landmarks. It‚Äôs a global leader in many fields and a melting pot of cultures and traditions.\n```\n:::\n:::\n\n\n## Chat using the chat API endpoint\n\nThe ollama chat endpoint takes several parameters such as model, messages, and stream. The messages parameter is a list of dictionaries. Each dictionary contains two keys - a role and content. Message Role can be \"user\", \"system\",or \"assistant\"\n\nBy default, each chat generates a new response and does not preserve history.\n\n::: {#3b857a2f .cell execution_count=7}\n``` {.python .cell-code}\nres = ollama.chat(\n    model = \"gemma3:4b\", \n    messages = [\n        {\"role\": \"user\",\"content\":\"Hello, how are you?\"}\n        ]              \n    )\n```\n:::\n\n\n::: {#b303a777 .cell execution_count=8}\n``` {.python .cell-code}\nres[\"message\"][\"content\"]\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```\n\"I‚Äôm doing well, thank you for asking! As a large language model, I don't really *feel* in the way humans do, but my systems are running smoothly and I‚Äôm ready to chat. üòä \\n\\nHow are *you* doing today? Is there anything you‚Äôd like to talk about or anything I can help you with?\"\n```\n:::\n:::\n\n\nGenerate a streaming response.\n\n::: {#540085d1 .cell execution_count=9}\n``` {.python .cell-code}\nres = ollama.chat(\n    model = \"gemma3:4b\", \n    messages = [\n        {\"role\": \"user\",\"content\":\"tell me about Toronto in 2 lines?\"}\n        ],\n    stream = True              \n    )\n```\n:::\n\n\n::: {#1dd08c62 .cell execution_count=10}\n``` {.python .cell-code}\nfor chunk in res:\n    print(chunk.message.content, end = \"\", flush = True)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nToronto is a vibrant, multicultural metropolis ‚Äì Canada's largest city ‚Äì known for its diverse neighborhoods, iconic CN Tower, and thriving arts and culture scene. It‚Äôs a bustling hub of finance, innovation, and entertainment, offering something for everyone.\n```\n:::\n:::\n\n\n# Preserve the chat history by appending messages\n\nTo keep a history of the messages, we can keep appending messages in the list\n\nReference: https://github.com/ollama/ollama-python/issues/242\n\n::: {#f4f4c516 .cell execution_count=11}\n``` {.python .cell-code}\nmodel = \"gemma3:4b\"\nmessages = []\ndef chat(message):\n    # Define the messages parameter\n    user_message = {\n        \"role\": \"user\",\n        \"content\": message\n    }\n    messages.append(user_message)\n    # Call the model\n    response = ollama.chat(model = model, messages = messages, stream = False)\n    answer = response.message.content\n    messages.append(response.message)\n    return answer\n\nanswer = chat(\"Tell me about Toronto in 2 lines.\")\nMarkdown(answer)\n```\n\n::: {.cell-output .cell-output-display .cell-output-markdown execution_count=11}\nToronto is a vibrant, multicultural metropolis ‚Äì Canada‚Äôs largest city ‚Äì known for its iconic skyline, diverse neighborhoods, and thriving arts and culture scene. It‚Äôs a bustling hub of finance, innovation, and entertainment, offering something for everyone.\n:::\n:::\n\n\n::: {#370394c3 .cell execution_count=12}\n``` {.python .cell-code}\nanswer = chat(\"Tell me two more things about Toronto in 2 lines.\")\nMarkdown(answer)\n```\n\n::: {.cell-output .cell-output-display .cell-output-markdown execution_count=12}\nOkay, here are two more facts about Toronto in two lines each:\n\nToronto boasts an impressive network of green spaces, including sprawling parks like High Park and the Don Valley trails, offering respite from the urban bustle. \n\nIt‚Äôs also a major center for film and television production, earning it the nickname ‚ÄúHollywood North‚Äù and attracting talent from around the globe.\n:::\n:::\n\n\n::: {#0f2d23be .cell execution_count=13}\n``` {.python .cell-code}\nanswer = chat(\"My name is Shefali\")\nMarkdown(answer)\n```\n\n::: {.cell-output .cell-output-display .cell-output-markdown execution_count=13}\nHello Shefali! It‚Äôs lovely to meet you. Is there anything you‚Äôd like to chat about or perhaps you have a question for me?\n:::\n:::\n\n\n::: {#b8307db8 .cell execution_count=14}\n``` {.python .cell-code}\nanswer = chat(\"Do you remember my name?\")\nMarkdown(answer)\n```\n\n::: {.cell-output .cell-output-display .cell-output-markdown execution_count=14}\nAbsolutely! You told me your name is Shefali. It‚Äôs nice to remember things! üòä \n\nIs there anything you‚Äôd like to talk about, Shefali?\n:::\n:::\n\n\nLook at the messages so far in history.\n\n::: {#6d74c4c7 .cell execution_count=15}\n``` {.python .cell-code}\nmessages\n```\n\n::: {.cell-output .cell-output-display execution_count=15}\n```\n[{'role': 'user', 'content': 'Tell me about Toronto in 2 lines.'},\n Message(role='assistant', content='Toronto is a vibrant, multicultural metropolis ‚Äì Canada‚Äôs largest city ‚Äì known for its iconic skyline, diverse neighborhoods, and thriving arts and culture scene. It‚Äôs a bustling hub of finance, innovation, and entertainment, offering something for everyone.', images=None, tool_calls=None),\n {'role': 'user',\n  'content': 'Tell me two more things about Toronto in 2 lines.'},\n Message(role='assistant', content='Okay, here are two more facts about Toronto in two lines each:\\n\\nToronto boasts an impressive network of green spaces, including sprawling parks like High Park and the Don Valley trails, offering respite from the urban bustle. \\n\\nIt‚Äôs also a major center for film and television production, earning it the nickname ‚ÄúHollywood North‚Äù and attracting talent from around the globe.', images=None, tool_calls=None),\n {'role': 'user', 'content': 'My name is Shefali'},\n Message(role='assistant', content='Hello Shefali! It‚Äôs lovely to meet you. Is there anything you‚Äôd like to chat about or perhaps you have a question for me?', images=None, tool_calls=None),\n {'role': 'user', 'content': 'Do you remember my name?'},\n Message(role='assistant', content='Absolutely! You told me your name is Shefali. It‚Äôs nice to remember things! üòä \\n\\nIs there anything you‚Äôd like to talk about, Shefali?', images=None, tool_calls=None)]\n```\n:::\n:::\n\n\n# Look at the running models\n\n::: {#0c786d90 .cell execution_count=16}\n``` {.python .cell-code}\nfor model in ollama.ps().models:\n    print(model.model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ngemma3:4b\n```\n:::\n:::\n\n\nUnfortunately, the python library does not provide a function to stop a running model.\n\n",
    "supporting": [
      "02_use_ollama_python_library_files"
    ],
    "filters": [],
    "includes": {}
  }
}